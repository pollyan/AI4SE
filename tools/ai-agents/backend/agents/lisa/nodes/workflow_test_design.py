"""
Workflow Test Design Node - æµ‹è¯•è®¾è®¡å·¥ä½œæµèŠ‚ç‚¹

å¤„ç†æµ‹è¯•è®¾è®¡å·¥ä½œæµçš„æ ¸å¿ƒé€»è¾‘ï¼ŒåŒ…æ‹¬éœ€æ±‚æ¾„æ¸…ã€ç­–ç•¥åˆ¶å®šã€ç”¨ä¾‹ç¼–å†™å’Œæ–‡æ¡£äº¤ä»˜ã€‚
"""

import logging
import re
from typing import Any, List, Dict

from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from langgraph.config import get_stream_writer

from ..state import LisaState, ArtifactKeys
from ..schemas import UpdateArtifact
from ..prompts.workflows import build_workflow_prompt
from backend.agents.shared.artifact_summary import get_artifacts_summary
from ..prompts.artifacts import (
    ARTIFACT_CLARIFY_REQUIREMENTS,
    ARTIFACT_STRATEGY_BLUEPRINT,
    ARTIFACT_CASES_SET,
    ARTIFACT_DELIVERY_FINAL,
    ARTIFACT_REQ_REVIEW_RECORD
)
from backend.agents.shared.data_stream import (
    stream_tool_call,
    stream_tool_result
)

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# é»˜è®¤è®¡åˆ’å®šä¹‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DEFAULT_TEST_DESIGN_PLAN: List[Dict[str, str]] = [
    {"id": "clarify", "name": "éœ€æ±‚æ¾„æ¸…", "status": "pending"},
    {"id": "strategy", "name": "ç­–ç•¥åˆ¶å®š", "status": "pending"},
    {"id": "cases", "name": "ç”¨ä¾‹è®¾è®¡", "status": "pending"},
    {"id": "delivery", "name": "æ–‡æ¡£äº¤ä»˜", "status": "pending"},
]

DEFAULT_REQUIREMENT_REVIEW_PLAN: List[Dict[str, str]] = [
    {"id": "clarify", "name": "éœ€æ±‚æ¾„æ¸…", "status": "pending"},
    {"id": "analysis", "name": "éœ€æ±‚åˆ†æ", "status": "pending"},
    {"id": "risk", "name": "é£é™©è¯„ä¼°", "status": "pending"},
    {"id": "report", "name": "è¯„å®¡æŠ¥å‘Š", "status": "pending"},
]

# äº§å‡ºç‰©æ¨¡æ¿å…ƒæ•°æ®
ARTIFACT_TEMPLATES_TEST_DESIGN = [
    {"stage_id": "clarify", "artifact_key": "test_design_requirements", "name": "éœ€æ±‚æ¾„æ¸…æŠ¥å‘Š"},
    {"stage_id": "strategy", "artifact_key": "test_design_strategy", "name": "æµ‹è¯•ç­–ç•¥è“å›¾"},
    {"stage_id": "cases", "artifact_key": "test_design_cases", "name": "æµ‹è¯•ç”¨ä¾‹é›†"},
    {"stage_id": "delivery", "artifact_key": "test_design_final", "name": "äº¤ä»˜æ–‡æ¡£"},
]

ARTIFACT_TEMPLATES_REQUIREMENT_REVIEW = [
    {"stage_id": "clarify", "artifact_key": "req_review_record", "name": "éœ€æ±‚è¯„å®¡è®°å½•"},
    {"stage_id": "analysis", "artifact_key": "req_review_record", "name": "éœ€æ±‚è¯„å®¡è®°å½•"},
    {"stage_id": "risk", "artifact_key": "req_review_risk", "name": "é£é™©è¯„ä¼°æŠ¥å‘Š"},
    {"stage_id": "report", "artifact_key": "req_review_report", "name": "è¯„å®¡æŠ¥å‘Š"},
]

def get_artifact_templates(workflow_type: str) -> List[Dict[str, str]]:
    """è·å–å·¥ä½œæµå¯¹åº”çš„äº§å‡ºç‰©æ¨¡æ¿å…ƒæ•°æ®"""
    if workflow_type == "requirement_review":
        return ARTIFACT_TEMPLATES_REQUIREMENT_REVIEW
    return ARTIFACT_TEMPLATES_TEST_DESIGN


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è¾…åŠ©å‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_default_plan(workflow_type: str) -> List[Dict[str, str]]:
    """è·å–å·¥ä½œæµçš„é»˜è®¤è®¡åˆ’"""
    if workflow_type == "requirement_review":
        return [dict(s) for s in DEFAULT_REQUIREMENT_REVIEW_PLAN]
    return [dict(s) for s in DEFAULT_TEST_DESIGN_PLAN]


def get_stage_index(plan: List[Dict], stage_id: str) -> int:
    """è·å–é˜¶æ®µåœ¨è®¡åˆ’ä¸­çš„ç´¢å¼•"""
    for i, stage in enumerate(plan):
        if stage.get("id") == stage_id:
            return i
    return 0


def update_plan_status(plan: List[Dict], current_stage_id: str) -> None:
    """æ›´æ–°è®¡åˆ’ä¸­å„é˜¶æ®µçš„çŠ¶æ€"""
    current_idx = get_stage_index(plan, current_stage_id)
    for i, stage in enumerate(plan):
        if i < current_idx:
            stage["status"] = "completed"
        elif i == current_idx:
            stage["status"] = "active"
        else:
            stage["status"] = "pending"

def determine_stage(state: LisaState, workflow_type: str) -> str:
    """
    æ ¹æ®äº§å‡ºç‰©ç¡®å®šå½“å‰é˜¶æ®µ
    
    Args:
        state: å½“å‰çŠ¶æ€
        workflow_type: å·¥ä½œæµç±»å‹
    """
    artifacts = state.get("artifacts", {})
    
    if workflow_type == "requirement_review":
        # éœ€æ±‚è¯„å®¡æµç¨‹: clarify -> analysis -> risk -> report
        if ArtifactKeys.REQ_REVIEW_REPORT in artifacts:
            return "report"  # å·²å®Œæˆï¼Œåœç•™åœ¨æœ€åé˜¶æ®µæˆ–è¿›å…¥ç»“æŸ
        elif ArtifactKeys.REQ_REVIEW_RISK in artifacts:
            return "report"
        elif ArtifactKeys.REQ_REVIEW_RECORD in artifacts:
            return "risk"
        else:
            return "clarify"
            
    else:  # é»˜è®¤ä¸º test_design
        # æµ‹è¯•è®¾è®¡æµç¨‹: clarify -> strategy -> cases -> delivery
        if ArtifactKeys.TEST_DESIGN_FINAL in artifacts:
            return "delivery"
        elif ArtifactKeys.TEST_DESIGN_CASES in artifacts:
            return "delivery"
        elif ArtifactKeys.TEST_DESIGN_STRATEGY in artifacts:
            return "cases"
        elif ArtifactKeys.TEST_DESIGN_REQUIREMENTS in artifacts:
            return "strategy"
        else:
            return "clarify"


def get_artifact_template(key: str) -> str:
    """æ ¹æ® Artifact Key è·å–å¯¹åº”çš„ Markdown æ¨¡æ¿"""
    if key == ArtifactKeys.TEST_DESIGN_REQUIREMENTS: return ARTIFACT_CLARIFY_REQUIREMENTS
    if key == ArtifactKeys.TEST_DESIGN_STRATEGY: return ARTIFACT_STRATEGY_BLUEPRINT
    if key == ArtifactKeys.TEST_DESIGN_CASES: return ARTIFACT_CASES_SET
    if key == ArtifactKeys.TEST_DESIGN_FINAL: return ARTIFACT_DELIVERY_FINAL
    if key == ArtifactKeys.REQ_REVIEW_RECORD: return ARTIFACT_REQ_REVIEW_RECORD
    return ""

def get_artifact_key_for_stage(stage: str, workflow_type: str) -> str | None:
    """è·å–é˜¶æ®µå¯¹åº”çš„äº§å‡ºç‰© Key"""
    if workflow_type == "requirement_review":
        stage_to_artifact = {
            "clarify": ArtifactKeys.REQ_REVIEW_RECORD,
            "analysis": ArtifactKeys.REQ_REVIEW_RECORD,
            "risk": ArtifactKeys.REQ_REVIEW_RISK,
            "report": ArtifactKeys.REQ_REVIEW_REPORT,
        }
    else:
        stage_to_artifact = {
            "clarify": ArtifactKeys.TEST_DESIGN_REQUIREMENTS,
            "strategy": ArtifactKeys.TEST_DESIGN_STRATEGY,
            "cases": ArtifactKeys.TEST_DESIGN_CASES,
            "delivery": ArtifactKeys.TEST_DESIGN_FINAL,
        }
    return stage_to_artifact.get(stage)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¸»èŠ‚ç‚¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def workflow_execution_node(state: LisaState, llm: Any) -> LisaState:
    """
    é€šç”¨å·¥ä½œæµæ‰§è¡ŒèŠ‚ç‚¹
    
    èƒ½å¤Ÿå¤„ç† test_design å’Œ requirement_review ä¸¤ç§å·¥ä½œæµã€‚
    ä½¿ç”¨ get_stream_writer() å®æ—¶æ¨é€è¿›åº¦å’Œäº§å‡ºç‰©æ›´æ–°ã€‚
    """
    # è·å– StreamWriter ç”¨äºå®æ—¶æ¨é€è¿›åº¦
    writer = get_stream_writer()
    
    # è·å–å½“å‰å·¥ä½œæµç±»å‹ï¼Œé»˜è®¤ä¸º test_design
    workflow_type = state.get("current_workflow") or "test_design"
    logger.info(f"æ‰§è¡Œå·¥ä½œæµ: {workflow_type}")
    
    # ç¡®å®šå½“å‰é˜¶æ®µ (ä¼˜å…ˆä½¿ç”¨ current_stage_id)
    current_stage = state.get("current_stage_id") or state.get("workflow_stage")
    if not current_stage:
        current_stage = determine_stage(state, workflow_type)
    
    logger.info(f"å½“å‰é˜¶æ®µ: {current_stage}")
    
    # è·å–æˆ–åˆå§‹åŒ–è®¡åˆ’
    plan = state.get("plan") or get_default_plan(workflow_type)
    update_plan_status(plan, current_stage)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“ æ¨é€è¿›åº¦æ›´æ–°
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    writer({
        "type": "progress",
        "progress": {
            "stages": plan,
            "currentStageIndex": get_stage_index(plan, current_stage),
            "currentTask": f"æ­£åœ¨å¤„ç† {current_stage} é˜¶æ®µ...",
            "artifact_templates": get_artifact_templates(workflow_type)
        }
    })
    logger.info(f"StreamWriter æ¨é€è¿›åº¦: stage={current_stage}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“ è‡ªåŠ¨åˆå§‹åŒ–äº§å‡ºç‰©æ¨¡æ¿
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    target_artifact_key = get_artifact_key_for_stage(current_stage, workflow_type)
    
    if target_artifact_key:
        current_artifacts = state.get("artifacts", {})
        if target_artifact_key not in current_artifacts:
            # 1. è·å–æ¨¡æ¿
            template = get_artifact_template(target_artifact_key)
            if template:
                # 2. æ¨é€åˆå§‹åŒ–äº‹ä»¶ (ä½œä¸º Progress äº‹ä»¶)
                # æ„é€ ä¸´æ—¶ artifacts å­—å…¸ç”¨äºå‰ç«¯å±•ç¤º
                display_artifacts = current_artifacts.copy()
                display_artifacts[target_artifact_key] = template
                
                writer({
                    "type": "progress",
                    "progress": {
                        "stages": plan,
                        "currentStageIndex": get_stage_index(plan, current_stage),
                        "currentTask": f"æ­£åœ¨å¤„ç† {current_stage} é˜¶æ®µ...",
                        "artifact_templates": get_artifact_templates(workflow_type),
                        "artifacts": display_artifacts
                    }
                })
                logger.info(f"StreamWriter åˆå§‹åŒ–æ¨¡æ¿: {target_artifact_key}")
    
    # æ„å»ºä¸Šä¸‹æ–‡
    artifacts = state.get("artifacts", {})
    artifacts_summary = get_artifacts_summary(artifacts)
    pending = state.get("pending_clarifications", [])
    consensus = state.get("consensus_items", [])
    
    # æ„å»ºè¿›åº¦è®¡åˆ’ä¸Šä¸‹æ–‡
    plan = state.get("plan", [])
    plan_context_lines = []
    for step in plan:
        step_id = step.get("id", "")
        step_name = step.get("name", "")
        marker = "â†’ " if step_id == current_stage else "  "
        plan_context_lines.append(f"{marker}{step_id}: {step_name}")
    plan_context = "\n".join(plan_context_lines) if plan_context_lines else "(æ— è¿›åº¦è®¡åˆ’)"
    
    # ä½¿ç”¨ç»Ÿä¸€çš„ Prompt æ„å»ºå‡½æ•°
    system_prompt = build_workflow_prompt(
        workflow_type=workflow_type,
        stage=current_stage,
        artifacts_summary=artifacts_summary,
        pending_clarifications=", ".join(pending) if pending else "(æ— )",
        consensus_count=len(consensus),
        plan_context=plan_context,
    )
    
    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    messages = [SystemMessage(content=system_prompt)]
    for msg in state.get("messages", []):
        messages.append(msg)
    
    # ç»‘å®šå·¥å…·
    llm_with_tools = llm.model.bind_tools([UpdateArtifact])
    
    # æœ€ç»ˆæ±‡æ€»çš„æ¶ˆæ¯å†…å®¹
    final_content = ""
    
    # ç´¯è®¡çš„ Tool Args å­—ç¬¦ä¸² (ç”¨äºæµå¼è§£æ)
    accumulated_tool_args = {} # {tool_call_index: "args_string"}
    
    # [NEW] è®°å½•å·²è§è¿‡çš„ Tool Call Index -> ID æ˜ å°„ (ç”¨äº Data Stream Protocol)
    tool_call_ids = {} # {index: tool_call_id}
    
    # è°ƒç”¨ LLM (æ”¹ä¸º Stream æ¨¡å¼)
    try:
        # ä½¿ç”¨åŒæ­¥æµ (å› ä¸º Graph èŠ‚ç‚¹ç›®å‰æ˜¯åŒæ­¥çš„)
        stream = llm_with_tools.stream(messages)
        
        # æ”¶é›† chunks ç”¨äºæœ€ç»ˆçŠ¶æ€åˆæˆ
        collected_chunks = []
        
        for chunk in stream:
            collected_chunks.append(chunk)
            
            # 1. ç´¯åŠ æ–‡æœ¬å†…å®¹ (æ™®é€šå¯¹è¯)
            if chunk.content:
                final_content += str(chunk.content)
            
            # 2. å¤„ç† Tool Call Chunks (æµå¼æ›´æ–°äº§å‡ºç‰©)
            if chunk.tool_call_chunks:
                for tool_chunk in chunk.tool_call_chunks:
                    idx = tool_chunk["index"]
                    
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # Data Stream Protocol æ”¯æŒ (Phase 2)
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    if tool_chunk.get("name") == "UpdateArtifact":
                        # 1. Handle Start Event
                        if idx not in tool_call_ids:
                            # å°è¯•è·å– IDï¼Œè‹¥æ— åˆ™ç”Ÿæˆä¸´æ—¶ ID (é€šå¸¸é¦–ä¸ª chunk æœ‰ ID)
                            tc_id = tool_chunk.get("id") or f"call_{idx}"
                            tool_call_ids[idx] = tc_id
                            
                        # 2. Delta Event (Skipped for V2 simplified stream)
                        # pass

                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    # Legacy Partial JSON Parsing (Backward Compat)
                    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    if idx not in accumulated_tool_args:
                        accumulated_tool_args[idx] = ""
                    
                    # ç´¯åŠ å‚æ•°å­—ç¬¦ä¸²
                    if tool_chunk.get("args"):
                        accumulated_tool_args[idx] += tool_chunk["args"]
                        
                        # å°è¯•ä»ç´¯åŠ çš„å­—ç¬¦ä¸²ä¸­æå– markdown_body
                        # è¿™æ˜¯ä¸€ä¸ª "Best Effort" çš„æµå¼æå–ï¼Œä¸å¿…ç­‰å¾… JSON é—­åˆ
                        current_args_str = accumulated_tool_args[idx]
                        
                        # æŸ¥æ‰¾ "markdown_body": " ä¹‹åçš„å†…å®¹
                        # æå– key (å¦‚æœå·²å‡ºç°)
                        key_match = re.search(r'"key":\s*"([^"]+)"', current_args_str)
                        current_key = key_match.group(1) if key_match else None
                        
                        # æå– body (å¤„ç†è½¬ä¹‰å¼•å·)
                        body_start_pattern = r'"markdown_body":\s*"'
                        body_match = re.search(body_start_pattern, current_args_str)
                        
                        if current_key and body_match:
                            start_pos = body_match.end()
                            raw_body = current_args_str[start_pos:]
                            
                            # æˆªæ–­æœ«å°¾å¯èƒ½çš„æœªé—­åˆå¼•å· (ç®€å•å¯å‘å¼)
                            if raw_body.endswith('"') and len(raw_body) > 1 and raw_body[-2] != '\\':
                                raw_body = raw_body[:-1]
                            
                            # ç®€æ˜“ Unescape (ä»…å¤„ç†æœ€å¸¸è§çš„)
                            clean_body = raw_body.replace('\\n', '\n').replace('\\"', '"').replace('\\\\', '\\')
                            
                            # æ„é€ ä¸´æ—¶ artifacts ç”¨äºæ¨é€
                            stream_artifacts = dict(artifacts)
                            stream_artifacts[current_key] = clean_body
                            
                            writer({
                                "type": "progress",
                                "progress": {
                                    "stages": plan,
                                    "currentStageIndex": get_stage_index(plan, current_stage),
                                    "currentTask": f"æ­£åœ¨ç”Ÿæˆæ–‡æ¡£...",
                                    "artifacts": stream_artifacts
                                }
                            })

        # åˆå¹¶ chunks æ„é€ æœ€ç»ˆå“åº”
        if collected_chunks:
            # sum() é»˜è®¤ start=0ï¼Œä¼šå¯¼è‡´ 0 + Chunk æŠ¥é”™
            # æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨ç´¯åŠ æˆ–æŒ‡å®š start
            response = collected_chunks[0]
            for next_chunk in collected_chunks[1:]:
                response = response + next_chunk
        else:
            response = AIMessage(content="")

        response_content = str(response.content)
        
        # DEBUG LOGGING
        logger.warning(f"LLM Response Content Length: {len(response_content)}")
        if len(response_content) > 500:
            logger.warning(f"LLM Response tail (500 chars): {response_content[-500:]}")
        else:
            logger.warning(f"LLM Response full: {response_content}")
            
        new_artifacts = dict(artifacts)
        artifact_updated = False
        
        # ä¼˜å…ˆæ£€æŸ¥ Tool Calls
        if response.tool_calls:
            logger.info(f"æ£€æµ‹åˆ° Tool Calls: {len(response.tool_calls)}")
            for tool_call in response.tool_calls:
                if tool_call["name"] == "UpdateArtifact":
                    args = tool_call["args"]
                    key = args.get("key")
                    content = args.get("markdown_body")
                    
                    if key and content:
                        new_artifacts[key] = content
                        artifact_updated = True
                        logger.info(f"ToolCall æ›´æ–°äº§å‡ºç‰©: {key}")
                        
                        # æ¨é€æœ€ç»ˆæ›´æ–° (è™½ç„¶æµå¼å·²ç»æ¨è¿‡äº†ï¼Œä½†è¿™é‡Œç¡®ä¿ä¸€è‡´æ€§)
                        writer({
                            "type": "progress",
                            "progress": {
                                "stages": plan,
                                "currentStageIndex": get_stage_index(plan, current_stage),
                                    "currentTask": f"æ­£åœ¨å¤„ç† {current_stage} é˜¶æ®µ...",
                                "artifacts": new_artifacts
                            }
                        })
                        
                        # [NEW] æ¨é€ Tool Result äº‹ä»¶ (Data Stream Protocol)
                        writer({
                            "type": "data_stream_event",
                            "event": stream_tool_result(
                                tool_call_id=tool_call["id"],
                                tool_name="UpdateArtifact",
                                result={"key": key, "status": "completed"}
                            )
                        })
        
        # å¦‚æœæ²¡æœ‰ Tool Callï¼Œä¸”å†…å®¹éç©ºï¼Œåˆ™ä½œä¸ºæ™®é€šå¯¹è¯å¤„ç†
        # ç§»é™¤äº† Regex Fallbackï¼Œå¼ºåˆ¶è¦æ±‚æ¨¡å‹ä½¿ç”¨å·¥å…·ç”Ÿæˆæ–‡æ¡£
        if not artifact_updated:
             logger.info("æœªæ£€æµ‹åˆ° ToolCallï¼Œä½œä¸ºæ™®é€šå›å¤å¤„ç†")

        ai_message = AIMessage(content=response_content)
        
        # æ›´æ–°æ¶ˆæ¯å†å²
        new_messages = list(state.get("messages", []))
        new_messages.append(ai_message)
        
        # è¿”å›æ›´æ–°åçš„çŠ¶æ€
        return {
            **state,
            "messages": new_messages,
            "artifacts": new_artifacts,
            "workflow_stage": current_stage,
            "current_workflow": workflow_type,
        }
        
    except Exception as e:
        logger.error(f"æµ‹è¯•è®¾è®¡å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ï¼š{str(e)}")
        new_messages = list(state.get("messages", []))
        new_messages.append(error_message)
        
        return {
            **state,
            "messages": new_messages,
        }
